---
title: "Gewichtung in R"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  github_document:
    toc: true
    toc_depth: 2
---

# Verwendete neue Befehle

------------------------------------------------------------------------

`svydesign()` = Gewichteten Datensatz erstellen (survey)\
as_survey_design`()` = Gewichteten Datensatz erstellen für die Arbeit mit dplyr (srvyr)\
`survey_mean()` = Gewichteten Mittelwert berechnen (srvyr)\
`cascade()` = Berechnung und Anlegen mehrerer Variablen in einem Befehl (dplyr)\
`survey_var()` = Gewichtete Varianz berechnen (srvyr)\
`survey_quantile()` = Gewichtete Quantile berechnen (srvyr)\
`svyqqmath()` = Gewichteten QQPlot generieren (survey)\
`freq()` = Häufigkeitstabelle berechnen (summarytools)\
`descr()` = Deskriptive Statistiken berechnen (summarytools)

------------------------------------------------------------------------

# Pakete laden

Neben den bereits bekannten Paketen benötigen wir nun noch zusätzlich das *survey*-, *srvyr*- und *summarytools*-Paket.

Das *survey*-Paket ist unser zentralles Paket in diesem Skript, auch wenn dessen Funktion nicht so häufig aufgerufen werden. Mit diesem Paket werden Befehle bereit gestellt, die die Berücksichtung eines komplexen Erhebungsdesign, wie im ESS, über Gewichtung ermöglicht.

Das *srvyr*-Paket ist eine Ergänzung zu *survey* mit der wir in der gewohnten Struktur von *dplyr* weiter arbeiten können. *srvyr* übernimmt lediglich die Transformation der Daten in ein lesbares Format für *dplyr*. Die Gewichtung wird weiterhin mit Hilfe des *survey*-Paketes durchgeführt.

Das *summarytools*-Pakte gibt uns ähnlich wie *sjmisc* oder *psych* eine breite Palette von Befeheln mit denen wir die deskriptiven Statistiken berechnen können. Entgegen den anderen Paketen lässt sich *summarytools* gut mit *dplyr* und Gewichtung verbinden.

```{r, eval=FALSE}
install.packages("survey")
install.packages("srvyr")
install.packages("summarytools")
```

```{r, warning=FALSE, message=FALSE}
library(haven)
library(dplyr)
library(tidyr)
library(survey)
library(srvyr)
library(sjmisc)
library(sjPlot)
library(summarytools)
```

Datensatz wieder einlesen (Wenn nötig)

```{r}
data <- read_sav("ESS10_HV.sav")
```

# Gewichten

**Warum gewichten?**

In der Stichprobenentwicklung nutzen wir verschiedene Methoden um die zufällige Auswahl von Personen oder die Vergleichbarkeit verschiedener Gruppen (disproportional geschichte Stichprobe) zu gewährleisten. Dabei entstehen immer wieder gewollte wie auch ungewollte Verzerrungen in unseren Daten, wodurch manche Stimmen entgegen unserem Willen mehr Gewicht haben, als andere. Um diese Verzerrungen zu kompensieren werden in den meisten Umfragen Gewichtungsparameter mitgeliefert, die wir verwenden können.

In dem ESS werden verschiedene Parameter mitgeliefert, die unter <https://www.europeansocialsurvey.org/methodology/ess-methodology/data-processing-and-archiving/weighting> genauer betrachtet werden können.

Im Folgenden werden verschiedene Möglichkeiten aufgezeigt, mit denen die Gewichtungsparameter berücksichtigt werden können. Wie auch bei anderen Befehlen gibt es bei manchen Vor-und Nachteile, die je nach Situation abgewägt werden müssen.

## Mit gewichteten Daten arbeiten - s*urvey* und *srvyr*

Zum Anfang werden wir den gewichteten Datensatz definieren. Dies ist mit dem Befehl `svydesign()` des *survey*-Paketes oder mit `as_survey_design()` des *srvyr*-Paketes möglich.\
Folgend beide Variationen.

**Wichtig!**\
Je nachdem mit welchem ESS wir arbeiten müssen wir die Option `...(..., weights = ...)` anpassen. In dem ESS10 stehen uns alle Gewichtungsparameter zu Verfügung, weswegen wir mit dem empfohlenen `anweight` arbeiten. Im ESS11 ist dieses Gewicht noch nicht angegeben, da hier unter anderem das post-stratified design weight `pspwght` fehlt. Aus diesem Grund arbeiten wir im ESS11 notgedrungen mit `dweight`.

```{r}
data_weigth_survey <- svydesign(ids = ~psu, 
                                strata = ~stratum, 
                                weights = ~anweight, 
                                data = data, 
                                nest = TRUE)

data_weight_srvyr <- data %>% as_survey_design(ids = psu, 
                                               strata = stratum, 
                                               weights = anweight, 
                                               nest = TRUE)
```

Wie zu sehen sind, sie die beiden Funktionen sehr ähnlich im Aufbau.

`ids = ...` –\> Hier geben wir die Rangfolge der Cluster an. Diese sind vom ESS mit `psu` vorgegeben.\
`strata = ...` –\> Hier geben wir die Informationen zu den Schichten an. Wieder vorgegeben mit `stratum`\
`weights = ...` –\> Hier geben wir unseren Geichtungsparameter an. Für den ESS10 ist das `anweight` und für ESS11 `dweight`\
`data = ...` –\> Hier wird der Datensatz angegeben. Bei `as_survey_design` erfolgt dies vor dem Befehl `<- data %>% ...`\
`nest = TRUE` –\> Hiermit geben wir an, das es Überschneidungen zwischen Schichten und Cluster gibt. Die Cluster werden in die Schichten eingebettet.

Im folgenden arbeiten wir nun mit dem neuen Datensatz, der durch das *srvyr*-Paket entstanden ist.

Die Gewichtung führt nun zu unterschiedlichen Ergebnissen in den deskriptiven Analysen. Um das zu berücksichtigen können wir nun verschiedene Befehle zur erneuten Berechnung des Mittelwertes, der Standardabweichung, und vieles mehr, nutzen.

## Mittelwertberechnung

Für die Berechnung des Mittelwertes und dem dazugehörigen Konfidenzinterval verwenden wir die Funktion `survey_mean()` (*srvyr*). Eine weitere geläufige Funktion ist `svymean()` des *survey*-Paketes. Dieses wird aber hier nicht weiter berücksichtigt.\
In der Arbeit mit `survey_mean()` können wir leider nicht wie wir es gewohnt sind mit `select()` arbeiten. Anstelle von `select()` arbeiten wir nun mit dem Befehl `across()` des *dplyr-* oder mit `cascade()` des *srvyr-*Paketes. Die Befehle `filter()`, `group_by()`, `mutate()` und `summarise()` sind weiterhin möglich.

Der Befehl `survey_mean()` muss häufig mit `summarise()` oder mit `mutate()` verbunden werden. In den meisten Fällen ist es nicht möglich den Befehl allein auszuführen.

**Die Berechnung einer Variable**

```{r}
data_weight_srvyr %>% 
  summarise(mean = survey_mean(hv_power, na.rm = TRUE))

data_weight_srvyr %>% 
  filter(cntry == "GB") %>%
  summarise(mean = survey_mean(hv_power, na.rm = TRUE))
  
data_weight_srvyr %>% 
  filter(cntry %in% c("GB", "BE", "SI")) %>%
  group_by(cntry) %>%
  summarise(mean = survey_mean(hv_power, na.rm = TRUE))
```

Um den Mittelwert der gewichteten Daten zu errechnen rufen wir zuerst den gewichteten Datensatz `data_weight_srvyr` auf und passen diesen wie gewohnt und nach Bedarf mit `filter()` oder `group_by()` an.

Um den Mittelwert zu berechnen verwenden wir nun den `summarise()`-Befehl des *dplyr* Paketes, welche alle Werte einer Spalte zu einem Wert zusammenführt. In unseren Fall den Mittelwert. Diesen zusammengefassten Wert geben wir die Bezeichnung `mean` mit `summarise(mean = ...)`.

Die Berechnung des Mittelwertes erfolgt dann mit dem Befehl `survey_mean(...)`. Innerhalb dieses Befehles geben wir noch die Information der zu berechnenden Variable `hv_power` an und die Option dass die `NA`s entfernt werden sollen.

Neben den Mittelwert erhalten wir auch noch den Standardfehler (also inwieweit unsere Mittelwert von der Grundgesamtheit abweichen kann -Schätzung!).

**Die Berechnung mehrere Variablen Gleichzeitig**

Für die Berechnung mehrere Variablen gelichzeitig können wir auf `across()` des *dplyr*-Paketes oder auf `cascade()` des *srvyr*-Paketes zurückgreifen. Der Befehl `cascade()` funktioniert genauso wie der `summarise()`-Befehl, nur mit dem Unterschied das wir mehrere Werte berechnen können.

```{r}
data_weight_srvyr %>% 
  filter(cntry %in% c("GB", "BE", "SI")) %>%
  group_by(cntry) %>%
  summarise(across(c("hv_power", "hv_univ", "hv_achiev"), 
                   ~survey_mean(.,na.rm = TRUE)))

#oder mit cascade

data_weight_srvyr %>% 
  filter(cntry %in% c("GB", "BE", "SI")) %>%
  group_by(cntry) %>%
  cascade(mean_power = survey_mean(hv_power, na.rm = TRUE), 
          mean_univ = survey_mean(hv_univ, na.rm = TRUE), 
          mean_achiev = survey_mean(hv_achiev, na.rm = TRUE))
```

In `across(...)` geben wir wie im `lapply()`-Befehl (in dem Skript noch nicht behandelt) die Variablen an die wir in einem Befehl einsetzen möchten. Dabei werden zu erst die Variablen als Vektor mit `c(...)` angegeben und dann der auszuführende Befehl `survey_mean()` mit `~` davor. Die Stelle an der wir die Variablen einsetzen wollen wird wieder mit dem Platzhalter `.` markiert.

## Berechnung des Konfidenzintervalls

Die Berechnung des Konfidenzintervalls funktioniert mit den selben Befehlen die zuvor verwendet wurden. In `survey_mean()` wird lediglich die Option `survey_mean(..., vartype = "ci")` ergänzt. `ci` steht hier stellvertretend für Konfidenzintervall.

Mit der zusätzlichen Option `survey_mean(..., level = ...)` können wir zudem die Grenzen des Konfidenzintervalls festlegen.

**Wichtig:**\
Bei der Berechnung des **Konfidenzintervalls** werden bei `svymean()` und `survey_mean()` unterschiedliche Annahmen bezüglich der Freiheitsgrade angenommen (die Freiheitsgrade werden durch unterschiedliche Stichprobendesigns beeinflusst). Bei `svymean()` wird von einer Normalverteilung und bei `survey_mean()` von einer studentischen t-Verteilung (angepasst an das Design) ausgegangen. Aus diesem Grund können sich die Ergebnisse zwischen den beiden Funktionen unterscheiden. Will man mit `survey_mean()` das gleiche Ergebnis wie bei `svymean()`, so ergänzt man die Option `survey_mean(..., df = INF)`.

```{r}
data_weight_srvyr %>% 
  filter(cntry %in% c("GB", "BE", "SI")) %>%
  group_by(cntry) %>%
  summarise(across(c("hv_power", "hv_univ", "hv_achiev"), 
                   ~survey_mean(.,na.rm = TRUE, vartype = "ci")))

#Anpassung des Konfidenzintervalls auf 2,5% und 97,5%

data_weight_srvyr %>% 
  filter(cntry %in% c("GB", "BE", "SI")) %>%
  group_by(cntry) %>%
  summarise(across(c("hv_power", "hv_univ", "hv_achiev"), 
                   ~survey_mean(.,na.rm = TRUE, vartype = "ci", level = 0.975)))
```

## Berechnung Varianz und Quantile

```{r}
data_weight_srvyr %>% 
  filter(cntry %in% c("GB", "BE", "SI")) %>%
  group_by(cntry) %>%
  cascade(mean_power = survey_mean(hv_power, na.rm = TRUE),
          var_power = survey_var(hv_power, na.rm = TRUE),
          quan_power = survey_quantile(hv_power, quantiles = c(0.25, 0.5, 0.75), na.rm = TRUE))
```

## QQ-Plot

Die Gewichtung hat auch einen Einfluss auf die Verteilungsfunktion. Demnach empfiehlt es sich je nach Situation ebenso einen Blick darauf zu werfen. Die Erstellung des QQ-Plots ist mit dem Befehl `svyqqmath()` des *survey*-Paketes möglich. Wichtig ist zu beachten das wir jetzt mit dem gewichteten Datensatz `data_weight_survey`, anstelle von `data_weight_srvyr`, arbeiten.

Im folgenden ein Vergleich zwichen gewichteten und ungewichteten Daten (Zuerst ungewichtet, dann gewichtet)

```{r}
qqnorm(data$hv_power)

svyqqmath(~hv_power, design=data_weigth_survey)
```

# Absolute und relative Häufigkeit mit `frq()`

Für die Berechnung der gewichteten Häufigkeiten können wir die bereits bekannte Funktion `frq()` verwenden. Dafür ergänzen wir einfach die Opiton `frq(..., weights = ...)`.\
Beachte hier wieder die Unterschiedung der Gewichte in ESS10 und ESS11!

```{r}
data %>%
  filter(cntry %in% c("GB", "BE", "SI")) %>%
  group_by(cntry) %>%
  frq(lrscale, weights = anweight, out = "viewer")
```

# Deskriptive Statistiken mit *Summarytools*

Mit *summarytools* können wir ähnlich wie mit dem `describe()`-Befehl des *psych*-Paketes die relevantesten deskriptiven Statistiken mit einem Befehl ausgeben lassen. Dabei lässt sich dieser gut mit *dplyr* verknüpfen.

Wie folgt ein Beispiel:

**Beachte:**

Der Befehl `descr()` kommt sowohl in dem *sjmisc*, als auch in dem *summarytools*-Paket vor. Es kann demnach in manchen Situationen nötig sein, dass vor dem ausführen entweder die Pakete *sjmisc* und *sjPlot* deaktiviert werden müssen oder dass Paket vor dem auszuführenden Befehl ergänzt wird. Dies ist möglich mit

```         
detach("package:sjPlot", unload = TRUE)
detach("package:sjmisc", unload = TRUE)
```

oder mit

```         
summarytools::descr(...)
```

Je nach dem welches Paket ihr zuletzt aktiviert habt, wird es auf den einen oder anderen Befehl zurückgreifen

```{r}
#Häufigkeitstabelle
data %>%
  filter(cntry %in% c("GB", "BE", "SI")) %>%
  group_by(cntry) %>%
  freq(lrscale, weights = anweight)

#Deskriptive Analyse mit einer Variable
data %>%
  descr(hv_selfd, weights = .$anweight)

#Deskriptive Analyse mit mehreren Variablen unter verschiedenen Bedingungen

data %>%
  filter(cntry %in% c("GB", "IT", "BE")) %>%
  group_by(cntry) %>%
  select(hv_selfd, hv_power, hv_univ, anweight) %>%
  group_map(~summarytools::descr(., weights = .$anweight))
```

Bei der Ausgabe mehrerer Variablen fällt auf, dass es auch immer die deskriptiven Statistiken des Gewichtungsparameters ausgibt. Dies kann leider nicht verhindert werden (beziehungsweise nicht ohne den Code zu verkomplizieren).

Ebenso müssen wir in Kombination des Befehles `descr()` und `group_by()` noch `group_map()` einarbeiten. Dies führt dazu das wir die Länder nach ihrer Reihenfolge im Datensatz (alphabetisch) ausgegeben bekommen.
