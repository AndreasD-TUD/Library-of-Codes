---
title: "Mehrebenen Analyse"
author: "Andreas Deim"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  github_document:
    toc: true
    toc_depth: 2
---

# Verwendete neue Befehle

------------------------------------------------------------------------

`lmer()` = lineares Mehrebenen-Regressionsmodel erstellen (lme4)\
`screenreg()` = Regressionsmodell in verschiedenen Formaten ausgeben lassen (texreg)\
`ranef()` = Randem Effekts ausgeben lassen (lme4)\
`icc()` = Intraclass Korrelationskoeffizient berechnen lassen (performance)\
`plot_model()` = Regressionsmodell ploten (sjPlot)\
`anova()` = Varianzanalyse

------------------------------------------------------------------------

# Pakete installieren (falls notwendig)

```{r, eval = FALSE}
install.packages("lme4")
install.packages("multilevel")
install.packages("texreg")
install.packages("performance")
```

# Pakete Laden

```{r, message=FALSE}
library(haven)  
library(ggplot2)  
library(dplyr)  
library(tibble)
library(lme4)
library(multilevel)
library(texreg)
library(performance)
library(sjPlot)
```

Datensatz einlesen (Wenn nötig)

```{r}
data <- read_sav("ESS10_HV.sav") 
```

# Mehrebenenanalyse

## Null-Modell

Um zuerst feststellen ob es sich überhaupt lohnt eine Multilevelanalyse zu durchzuführen lässt sich das Null-Modell zu Rate ziehen. Mit diesem können wir im Weiteren die intraclass correlation berechnen, um festzustellen welcher Varianzanteil unseres Modelles durch die höhere Ebene (in unserem Fall: Länderebene) erklärt wird.

Um eine Mehrebenen-Analyse durchzuführen benötigen wir zu aller erst die Pakete *lme4* und *multilevel*. Mit Hilfe dieser Pakete können wir die Funktion `lmer()` nutzen.\
Für die Generierung unseres Null-Modells verwenden wir eine ähnliche Schreibweise, wie wir sie bei der linearen oder multiplen Regression kennen gelernt haben. Zusätzlich wird nun noch in Klammern die unabhängige Variable auf der höheren Ebene und mit einem `|` die höhere Ebene als solches ergänzt. Da wir in einem Mull-Modell keine unabhängigen Variablen angeben reduziert sich der Inhalt unserer Klammer auf `(1|cntry)`.

Mit `summary()` können wir uns wie gewohnt die Ergebnisse unseres Modells ausgeben lassen. Zusätzlich dazu haben wir die Möglichkeit mit `screenreg()` eine schönere Übersicht zu erhalten, welche wir uns mit `htmlreg()` als separates Dokument abspeichern zu können, um sie in einen Bericht ansehnlicher einzupflegen.

```{r}
model1 <- data %>%   
  filter(cntry %in% c("GB","BG", "GR", "NL", "BE", "CH", "PT", "HU", "IT", "SK")) %>%
  lmer(trstsci ~ 1 + (1|cntry), data= ., weights = anweight) 
summary(model1)

screenreg(model1)
#htmlreg(model1, file = "Multilevel_Nullmodel.html")

```

## ICC

Die intraclass correlation gibt uns den Anteil der Varianzerklärung an, welcher durch die höhere Ebene erklärt wird.\
Diese können wir händisch aus den Werten des zuvor entwickelten Modelles berechnen mit der Formel:

$$
ICC = \frac{\sigma^2_{\text{between}}}{\sigma^2_{\text{between}} + \sigma^2_{\text{within}}}
$$

In unserem Beispiel wäre dies:

$$
ICC = \frac{\text{var:cntry}}{\text{var:cntry} + \text{var:Residual}} = \frac{0.16}{0.16 + 3.92} = 0.039
$$

Mit diesem Ergebnis können wir vermuten, dass unsere abhängige Variable nur geringfügig durch die Ländervariable beeinflusst wird. Die Gruppenunterscheidung kann nahezu vernachlässigt werden.

Alternativ lässt sich mit Hilfe des Paketes *performance* und dem Befehl `icc()` ebenso die intraclass correlation berechnen.

```{r}
icc(model1)
```

## Random Intercepts, Fixed Slopes

In der Mehrebenenanalyse könenn wir je nachdem Unterscheiden ob unsere höhere Ebene einen statischen oder dynamischen Einfluss haben soll. Im ersteren Fall reden wir von Random Intercepts und Fixed Slopes. Dies bedeutet das mein Intercept in jeder Gruppe varieren kann aber der Regressionsparameter der unabhängigen Variablen immer der gleiche bleibt. Egal ob wir Deutschland oder Frankreich betrachten, der Einfluss des allgemeinen Vertrauens in Menschen wirkt sich überall gleich auf das Vertrauen in Wissenschaftler:innen aus.

Im folgenden das Beispiel.

1.  Mit dem Befehl `plot_model()` des Paketes *sjPlot* können wir uns die varierenden Grafisch anzeigen und mit dem Befehl `ranef()` auch direkt als Zahl ausgeben lassen.

```{r}
model2 <- data %>%   
  filter(cntry %in% c("GB","BG", "GR", "NL", "BE", "CH", "PT", "HU", "IT", "SK")) %>%
  filter(!is.na(ppltrst)) %>%
  lmer(trstsci ~ ppltrst + (1|cntry), data= ., weights = anweight)

plot_model(model2, type = "re", show.values = TRUE, value.offset = .4)
ranef(model2)

screenreg(c(model1, model2))
```

## Random Intercepts, Random Slopes

Sofern die Notwendigkeit besteht können wir ebenso noch zulassen, dass die unabhängigen Variablen auf der höheren Ebene einen unterschiedlichen Einfluss haben.

Im folgenden könnten wir annehmen, dass die dass das Vertrauen in Menschen in jedem Land einen anderen Einfluss auf das Vertrauen in Wissenschaftler:innen hat.

**Wichtig** ist es an dieser Stelle die unabhägigen Variablen zu zentralisieren.\
Dies machen wir einfach in der Zeile `mutate(ppltrst = scale(ppltrst, scale = FALSE)) %>%`

```{r}

model3 <- data %>%   
  filter(cntry %in% c("GB","BG", "GR", "NL", "BE", "CH", "PT", "HU", "IT", "SK")) %>%
  filter(!is.na(ppltrst)) %>%
  mutate(ppltrst = scale(ppltrst, scale = FALSE)) %>%
  lmer(trstsci ~ ppltrst + (ppltrst|cntry), data= ., weights = anweight)

plot_model(model3, type = "re", show.values = TRUE, value.offset = .4)
ranef(model3)

screenreg(c(model1, model2, model3))
```

## Modellgüte

Ob sich ein Modell verbessert hat lässt sich vor allem an den Werten AIC und BIC ablesen. Je kleiner diese sind desto besser.

Genauer können wir eine Verbesserung des Modells allerdings mit dem Befehl `anova()` nachvollziehen. Ist der unterschied zwischen den Modellen signifikant, so können wir von einer Modellverbesserung reden und das komplexere Modell annehmen.

Da hinter jedem Model die selbe Anzahl an Personen stehen muss, müssen wir noch unser `model1` anpassen. Hier wurden bis dato auch die Personen berücksichtigt, die keine Angaben zu `ppltrst` gemacht haben.

```{r}
model1 <- data %>%   
  filter(cntry %in% c("GB","BG", "GR", "NL", "BE", "CH", "PT", "HU", "IT", "SK")) %>%
  filter(!is.na(ppltrst)) %>%
  lmer(trstsci ~ 1 + (1|cntry), data= ., weights = anweight) 


anova(model1, model2, model3)
```
